---
title: "Introduction to StatComp22011"
author: "Yuanyuan Yan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StatComp22011}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

## Overview

__StatComp22011__ is a R package developed to solve the two categories classification problem in medical field. Two functions are considered, namely, _SMAP_weights_()  and traditional method _logistic_regression_() (predicting the response using eighteen variables). The former is written in R version and the latter is written in Rcpp. Namely  _SMAP_weights_ for R and _logistic_regression_ for C++. 

##Function
Compared with logistics regression, SMAP(semi-parameter moving average method) avoid the process of model selection and the results are more robust when the model form is misspecified. Though many scholars have used this method to classification problems, they use the training set to estimate the model weights, which deviates from their aim of predicting the optimal outcome. Thus, I improved this method by inserting a validation set to estimate the model weights and allowing discrete variables in the explanatory variables.

The _SMAP_weights_ function can give the estimated model weights and the hitrate of both the original SMAP methods and improved SMAP methods to make comparison. And the Rcpp function _logistic_regression_ can return the results of traditional logistic regression method to compare with those of the semi-parameter models.

##Data
The dataset twotypeVehicle contains 430 samples. Each sample has 18 attributes and a vehicle type either "bus" or "opel". This dataset can be used to build a two catergories classification model.

The source R code for _SMAP_weights_  is as follows:
```{r,eval=FALSE}
SMAP_weights<-function(data,p,p_dis,n_D){
  #编写函数Design.matrix
  Design.matrix <- function(U, x, kn, degree,p,n)
  {
    q=kn+degree+1
    B=bSpline(U,df=q,intercept=TRUE,degree=degree)          
    Num<-p*(q)
    xx<-matrix(0,n,Num)
    Bb<-array(0,dim=c(p,Num,n)) 
    for (j in 1:n)  
    {
      for (i in 1:p)
      {Bb[i,((i-1)*(q)+1):(i*(q)),j]<-B[j,] }
      xx[j,]<-x[j,]%*%Bb[,,j]
    }
    design = list(Bb = Bb, xx = xx,B=B)
    return(design)
  } 
  
  ###数据输入
  realdata<-data
  J=2#二分类预测问题
  HitRite<-0
  HitRite1<-0
  HAT.W.VEC_B=matrix(0,1,p-p_dis)
  HAT.W.VEC_B_new=matrix(0,1,p-p_dis)
  ##############改进后的权重分析###############
  ############model averaging varying coefficient model#(SMAP)
  ####estimate model weights################
  ####B-spline################
  #数据集划分(训练集：测试集：验证集=8:1:1)
  train.rows<-sample(n_D,n_D*0.8)
  valid.rows<-sample(setdiff(seq(1:n_D),train.rows),n_D*0.1)
  test.rows<-setdiff(seq(1:n_D),union(train.rows,valid.rows))
  train<-realdata[train.rows,]
  valid<-realdata[valid.rows,]
  test<-realdata[test.rows,]
  
  n_tr=dim(train)[1];n_val=dim(valid)[1];n_test=dim(test)[1]
  x_tr=train[,1:p]
  y_tr_sta=train[,(p+1)]
  y_tr_sta[which(y_tr_sta==0)]=2
  y_tr=matrix(0,n_tr,2)
  y_tr[which(y_tr_sta==1),1]=1
  y_tr[which(y_tr_sta==2),2]=1
  #y_sta_tr=y_sta_D[out]
  x_val=valid[,1:p]
  y_val_sta=valid[,(p+1)]
  y_val_sta[which(y_val_sta==0)]=2
  y_val=matrix(0,n_val,2)
  y_val[which(y_val_sta==1),1]=1
  y_val[which(y_val_sta==2),2]=1
  x_test=test[,1:p]
  y_test_sta=test[,(p+1)]
  y_test_sta[which(y_test_sta==0)]=2
  y_test=matrix(0,n_test,2)
  y_test[which(y_test_sta==1),1]=1
  y_test[which(y_test_sta==2),2]=1
  
  n=n_D-n_test-n_val
  kn=floor((n)^(1/5));degree=1;q=kn+degree+1
  h=1*(((J-1)*p)/n)^(0.2)
  
  
  #############bspline改进前###########################
  hat.P=array(0,dim=c(n_tr,2,p-p_dis))
  hat.P.test=array(0,dim=c(n_test,2,p-p_dis))
  for (j in 1:(p-p_dis)){
    x_sub=Design.matrix(x_tr[,j+p_dis], as.matrix(cbind(1,x_tr[,-(j+p_dis)])),kn,degree,p=p,n=n_tr)$xx
    x_test_sub=Design.matrix(x_test[,j+p_dis],as.matrix(cbind(1,x_test[,-(j+p_dis)])),kn, degree,p=p,n=n_test)$xx
    lm0=multinom(y_tr~x_sub+0)
    hat.P[,,j]=lm0$fitted.values
    
    hat.mu1=x_test_sub%*%(coefficients(lm0)[1,])
    hat.p1=1/(1+exp(hat.mu1))
    hat.p2=exp(hat.mu1)/(1+exp(hat.mu1))
    hat.P.test[,,j]=cbind(hat.p1,hat.p2)
  }
  
  hat.P.A=y.vec=NULL 
  for(c0 in 1:n_tr) {
    hat.P.A=rbind(hat.P.A,hat.P[c0,,])
    y.vec=c(y.vec,y_tr[c0,])
  }
  lm.opt=solve.QP(Dmat=t(hat.P.A)%*%hat.P.A, 
                  dvec=t(y.vec)%*%hat.P.A, Amat=cbind(rep(1,p-p_dis),diag(p-p_dis)),
                  bvec=c(1,rep(0,p-p_dis)), meq=1) 
  w.opt=lm.opt$solution
  HAT.W.VEC_B[1,]=w.opt
  
  Hat.w.P=matrix(0,n_test,2)
  for(i in 1:n_test){
    for(j in 1:J){
      Hat.w.P[i,j]=sum(hat.P.test[i,j,]*w.opt) 
    }
  }
  Hat.y=apply(Hat.w.P,1,which.max)
  HitRate=mean(Hat.y==y_test_sta)
  
  
  #############bspline改进后###########################
  hat.P.val=array(0,dim=c(n_val,2,p-p_dis))
  hat.P.test=array(0,dim=c(n_test,2,p-p_dis))
  for (j in 1:(p-p_dis)){
    x_sub=Design.matrix(x_tr[,j+p_dis], as.matrix(cbind(1,x_tr[,-(j+p_dis)])),kn,degree,p=p,n=n_tr)$xx
    x_val_sub=Design.matrix(x_val[,j+p_dis],as.matrix(cbind(1,x_val[,-(j+p_dis)])),kn,degree,p=p,n=n_val)$xx
    x_test_sub=Design.matrix(x_test[,j+p_dis],as.matrix(cbind(1,x_test[,-(j+p_dis)])),kn, degree,p=p,n=n_test)$xx
    lm0=multinom(y_tr~x_sub+0)
    #hat.P[,,j]=lm0$fitted.values
    
    hat.mu1_val=x_val_sub%*%(coefficients(lm0)[1,])
    hat.p1_val=1/(1+exp(hat.mu1_val))
    hat.p2_val=exp(hat.mu1_val)/(1+exp(hat.mu1_val))
    hat.P.val[,,j]=cbind(hat.p1_val,hat.p2_val)
    
    hat.mu1=x_test_sub%*%(coefficients(lm0)[1,])
    hat.p1=1/(1+exp(hat.mu1))
    hat.p2=exp(hat.mu1)/(1+exp(hat.mu1))
    hat.P.test[,,j]=cbind(hat.p1,hat.p2)
  }
  
  hat.P.A=y.vec=NULL 
  for(c0 in 1:n_val) {
    hat.P.A=rbind(hat.P.A,hat.P.val[c0,,])
    y.vec=c(y.vec,y_val[c0,])
  }
  
  lm.opt=solve.QP(Dmat=t(hat.P.A)%*%hat.P.A, 
                  dvec=t(y.vec)%*%hat.P.A, Amat=cbind(rep(1,(p-p_dis)),diag(p-p_dis)),
                  bvec=c(1,rep(0,p-p_dis)), meq=1) 
  w.opt=lm.opt$solution
  HAT.W.VEC_B_new[1,]=w.opt
  
  Hat.w.P=matrix(0,n_test,2)
  for(i in 1:n_test){
    for(j in 1:J){
      Hat.w.P[i,j]=sum(hat.P.test[i,j,]*w.opt) 
    }
  }
  Hat.y=apply(Hat.w.P,1,which.max)
  HitRate1=mean(Hat.y==y_test_sta)
  
  results<-list(rbind(HAT.W.VEC_B,HAT.W.VEC_B_new),rbind(HitRate,HitRate1))
  names(results)<-c("Weights","Accuracy")
  return(results)
}

```

Note that: the input dataset must be arrange in a form of:(x1,x2,..,xp,y)

Here belows is an example of using the R function  _SMAP_weights_ () 
```{r}
library(StatComp22011)
load("~/Desktop/StatComp22011/data/twotypeVehicle.rda")
mydata<-twotypeVehicle
SMAP_weights(mydata,18,0,430)
```

The source Rcpp code for _logistic regression_  is as follows:
```{Rcpp}
#include<vector>
#include<Rcpp.h>
#include<math.h>
#include<iostream>

using namespace std;
using namespace Rcpp;

vector<double> groundTruth;
vector<vector<double> > inputValues;
vector<double> weight;


long epochs = 10;
double lr = 0.001;
double e = 2.71828;


void updateWeight(double predicted, double expected, vector<double> inputs);
void getAcc();
double sigmoid(double z);


NumericVector logistic_regression(NumericMatrix explain, NumericVector response);

//' @title A logistic regression method using Rcpp
//' @description A logistic regression method using Rcpp
//' @param explain the design matrix 
//' @param response the response vector y
//' @return the estimated coefficients of variables
//' @export
// [[Rcpp::export]]
NumericVector logistic_regression(NumericMatrix explain, NumericVector response) {
  int nr = explain.nrow();
  int nc = explain.ncol();
  for (int i = 0; i < nc; i++) {
    weight.push_back(0.2);
  }
  long i, j;
  
  // fill every sample attribution of dataset
  for (int k = 0; k < nr; k++) {
    vector<double> inputRow;
    for (int kk = 0; kk < nc; kk++) {
      inputRow.push_back(explain(k, kk));
    }
    inputValues.push_back(inputRow);
  }
  
  // fill ground truth
  int n_true = response.size();
  for (int k = 0; k < n_true; k++) {
    groundTruth.push_back(response[k]);
  }
  
  while (epochs--) {
    // cout << "********************----" << epochs << endl;
    for (i = 0; i < inputValues.size(); i++) {
      double yhat, z = 0;
      for (j = 0; j < inputValues[0].size(); j++) {
        z += weight[j] * inputValues[i][j];
      }
      yhat = sigmoid(z);
      
      updateWeight(yhat, groundTruth[i], inputValues[i]);
    }
  }
  
  
  getAcc();
  NumericVector out(nc);
  for (int k = 0; k < nc; ++k) {
    out[k] = weight[k];
  }
  return out;
}

void updateWeight(double yhat, double groundTruth, vector<double> inputValue) {
  for (int i = 0; i < inputValue.size(); i++) {
    double gradientDescent;
    gradientDescent = (yhat - groundTruth) * inputValue[i];
    weight[i] = weight[i] - (lr * gradientDescent);
  }
}

double sigmoid(double z) {
  return 1/(1 + pow(e, (-1 * z)));
}

void getAcc() {
  
  long correct = 0, totalCases = inputValues.size();
  
  for (int i = 0; i < totalCases; i++) {
    double yhat, z = 0;
    for (int j = 0; j < inputValues[0].size(); j++) {
      z += weight[j] * inputValues[i][j];
    }
    
    
    yhat = (sigmoid(z) < 0.5) ? 0 : 1;
    
    correct += (yhat == groundTruth[i]);
    
  }
  //cout << "Accuracy is: " << (correct * 100) / (totalCases) << "%" << endl;
  
}
```

Here belows is an example of using the Rcpp function  _logistic regression_ ()
```{r}
mydata<-twotypeVehicle
matrixx<-as.matrix(mydata[,1:18])
y<-mydata[,19]
logistic_regression(matrixx,y)
```
The Accuracy is about 78%~80%(calculated it but cannot use "cout' in Rcpp )
